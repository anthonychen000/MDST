{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder: \n",
    "\n",
    "- You are being evaluated for compeletion and effort in this checkpoint. \n",
    "- Avoid manual labor / hard coding as much as possible, everything we've taught you so far are meant to simplify and automate your process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be working with the same `states_edu.csv` that you should already be familiar with from the tutorial.\n",
    "\n",
    "We investigated Grade 8 reading score in the tutorial. For this checkpoint, you are asked to investigate another test. Here's an overview:\n",
    "\n",
    "* Choose a specific response variable to focus on\n",
    ">Grade 4 Math, Grade 4 Reading, Grade 8 Math\n",
    "* Pick or create features to use\n",
    ">Will all the features be useful in predicting test score? Are some more important than others? Should you standardize, bin, or scale the data?\n",
    "* Explore the data as it relates to that test\n",
    ">Create at least 2 visualizations (graphs), each with a caption describing the graph and what it tells us about the data\n",
    "* Create training and testing data\n",
    ">Do you want to train on all the data? Only data from the last 10 years? Only Michigan data?\n",
    "* Train a ML model to predict outcome \n",
    ">Define what you want to predict, and pick a model in sklearn to use (see sklearn <a href=\"https://scikit-learn.org/stable/modules/linear_model.html\">regressors</a>.\n",
    "* Summarize your findings\n",
    ">Write a 1 paragraph summary of what you did and make a recommendation about if and how student performance can be predicted\n",
    "\n",
    "Include comments throughout your code! Every cleanup and preprocessing task should be documented.\n",
    "\n",
    "Of course, if you're finding this assignment interesting (and we really hope you do!), you are welcome to do more than the requirements! For example, you may want to see if expenditure affects 4th graders more than 8th graders. Maybe you want to look into the extended version of this dataset and see how factors like sex and race are involved. You can include all your work in this notebook when you turn it in -- just always make sure you explain what you did and interpret your results. Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Data Cleanup </h2>\n",
    "\n",
    "Import `numpy`, `pandas`, and `matplotlib`.\n",
    "\n",
    "(Feel free to import other libraries!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the \"states_edu.csv\" dataset and take a look at the head of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 PRIMARY_KEY                 STATE  YEAR  ENROLL  \\\n",
      "0               1992_ALABAMA               ALABAMA  1992     NaN   \n",
      "1                1992_ALASKA                ALASKA  1992     NaN   \n",
      "2               1992_ARIZONA               ARIZONA  1992     NaN   \n",
      "3              1992_ARKANSAS              ARKANSAS  1992     NaN   \n",
      "4            1992_CALIFORNIA            CALIFORNIA  1992     NaN   \n",
      "5              1992_COLORADO              COLORADO  1992     NaN   \n",
      "6           1992_CONNECTICUT           CONNECTICUT  1992     NaN   \n",
      "7              1992_DELAWARE              DELAWARE  1992     NaN   \n",
      "8  1992_DISTRICT_OF_COLUMBIA  DISTRICT_OF_COLUMBIA  1992     NaN   \n",
      "9               1992_FLORIDA               FLORIDA  1992     NaN   \n",
      "\n",
      "   TOTAL_REVENUE  FEDERAL_REVENUE  STATE_REVENUE  LOCAL_REVENUE  \\\n",
      "0      2678885.0         304177.0      1659028.0       715680.0   \n",
      "1      1049591.0         106780.0       720711.0       222100.0   \n",
      "2      3258079.0         297888.0      1369815.0      1590376.0   \n",
      "3      1711959.0         178571.0       958785.0       574603.0   \n",
      "4     26260025.0        2072470.0     16546514.0      7641041.0   \n",
      "5      3185173.0         163253.0      1307986.0      1713934.0   \n",
      "6      3834302.0         143542.0      1342539.0      2348221.0   \n",
      "7       645233.0          45945.0       420942.0       178346.0   \n",
      "8       709480.0          64749.0            0.0       644731.0   \n",
      "9     11506299.0         788420.0      5683949.0      5033930.0   \n",
      "\n",
      "   TOTAL_EXPENDITURE  INSTRUCTION_EXPENDITURE  ...  GRADES_4_G  GRADES_8_G  \\\n",
      "0          2653798.0                1481703.0  ...     57948.0     58025.0   \n",
      "1           972488.0                 498362.0  ...      9748.0      8789.0   \n",
      "2          3401580.0                1435908.0  ...     55433.0     49081.0   \n",
      "3          1743022.0                 964323.0  ...     34632.0     36011.0   \n",
      "4         27138832.0               14358922.0  ...    418418.0    363296.0   \n",
      "5          3264826.0                1642466.0  ...     50648.0     45025.0   \n",
      "6          3721338.0                2148041.0  ...     38058.0     33691.0   \n",
      "7           638784.0                 372722.0  ...      8272.0      8012.0   \n",
      "8           742893.0                 329160.0  ...      5832.0      5000.0   \n",
      "9         11305642.0                5166374.0  ...    164416.0    142372.0   \n",
      "\n",
      "   GRADES_12_G  GRADES_1_8_G  GRADES_9_12_G  GRADES_ALL_G  AVG_MATH_4_SCORE  \\\n",
      "0      41167.0           NaN            NaN      731634.0             208.0   \n",
      "1       6714.0           NaN            NaN      122487.0               NaN   \n",
      "2      37410.0           NaN            NaN      673477.0             215.0   \n",
      "3      27651.0           NaN            NaN      441490.0             210.0   \n",
      "4     270675.0           NaN            NaN     5254844.0             208.0   \n",
      "5      34533.0           NaN            NaN      612635.0             221.0   \n",
      "6      28366.0           NaN            NaN      488476.0             227.0   \n",
      "7       6129.0           NaN            NaN      104321.0             218.0   \n",
      "8       3433.0           NaN            NaN       80937.0             193.0   \n",
      "9     100835.0           NaN            NaN     1981407.0             214.0   \n",
      "\n",
      "   AVG_MATH_8_SCORE  AVG_READING_4_SCORE  AVG_READING_8_SCORE  \n",
      "0             252.0                207.0                  NaN  \n",
      "1               NaN                  NaN                  NaN  \n",
      "2             265.0                209.0                  NaN  \n",
      "3             256.0                211.0                  NaN  \n",
      "4             261.0                202.0                  NaN  \n",
      "5             272.0                217.0                  NaN  \n",
      "6             274.0                222.0                  NaN  \n",
      "7             263.0                213.0                  NaN  \n",
      "8             235.0                188.0                  NaN  \n",
      "9             260.0                208.0                  NaN  \n",
      "\n",
      "[10 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/states_edu.csv\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should always familiarize yourself with what each column in the dataframe represents. Read about the states_edu dataset here: https://www.kaggle.com/noriuk/us-education-datasets-unification-project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this space to rename columns, deal with missing data, etc. _(optional)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exploratory Data Analysis (EDA) </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chosen one of Grade 4 Reading, Grade 4 Math, or Grade 8 Math to focus on: Grade 4 Math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many years of data are logged in our dataset? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "kek = df['YEAR'].nunique()\n",
    "print(kek)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare Michigan to Ohio. Which state has the higher average across all years in the test you chose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kek1 = df.groupby(\"STATE\")[\"AVG_MATH_4_SCORE\"].mean()\n",
    "\n",
    "michigan_average = kek1.loc[\"MICHIGAN\"]\n",
    "ohio_average = kek1.loc[\"OHIO\"]\n",
    "\n",
    "print(michigan_average > ohio_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the average for your chosen test across all states in 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236.32743362831857\n"
     ]
    }
   ],
   "source": [
    "avg = df[\"AVG_MATH_4_SCORE\"].mean()\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each state, find a maximum value for your chosen test score\n",
    "\n",
    "Refer to the `Grouping and Aggregating` section in Tutorial 0 if you are stuck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATE\n",
      "ALABAMA                 233.0\n",
      "ALASKA                  237.0\n",
      "ARIZONA                 240.0\n",
      "ARKANSAS                240.0\n",
      "CALIFORNIA              235.0\n",
      "COLORADO                247.0\n",
      "CONNECTICUT             245.0\n",
      "DELAWARE                243.0\n",
      "DISTRICT_OF_COLUMBIA    235.0\n",
      "DODEA                   250.0\n",
      "FLORIDA                 246.0\n",
      "GEORGIA                 240.0\n",
      "HAWAII                  243.0\n",
      "IDAHO                   242.0\n",
      "ILLINOIS                239.0\n",
      "INDIANA                 249.0\n",
      "IOWA                    246.0\n",
      "KANSAS                  248.0\n",
      "KENTUCKY                242.0\n",
      "LOUISIANA               234.0\n",
      "MAINE                   246.0\n",
      "MARYLAND                247.0\n",
      "MASSACHUSETTS           253.0\n",
      "MICHIGAN                238.0\n",
      "MINNESOTA               253.0\n",
      "MISSISSIPPI             241.0\n",
      "MISSOURI                241.0\n",
      "MONTANA                 244.0\n",
      "NATIONAL                242.0\n",
      "NEBRASKA                246.0\n",
      "NEVADA                  237.0\n",
      "NEW_HAMPSHIRE           253.0\n",
      "NEW_JERSEY              249.0\n",
      "NEW_MEXICO              233.0\n",
      "NEW_YORK                243.0\n",
      "NORTH_CAROLINA          245.0\n",
      "NORTH_DAKOTA            246.0\n",
      "OHIO                    246.0\n",
      "OKLAHOMA                240.0\n",
      "OREGON                  240.0\n",
      "PENNSYLVANIA            246.0\n",
      "RHODE_ISLAND            242.0\n",
      "SOUTH_CAROLINA          238.0\n",
      "SOUTH_DAKOTA            242.0\n",
      "TENNESSEE               241.0\n",
      "TEXAS                   244.0\n",
      "UTAH                    244.0\n",
      "VERMONT                 248.0\n",
      "VIRGINIA                248.0\n",
      "WASHINGTON              246.0\n",
      "WEST_VIRGINIA           237.0\n",
      "WISCONSIN               245.0\n",
      "WYOMING                 248.0\n",
      "Name: AVG_MATH_4_SCORE, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "max = df.groupby(\"STATE\")[\"AVG_MATH_4_SCORE\"].max()\n",
    "print(max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Feature Engineering </h2>\n",
    "\n",
    "After exploring the data, you can choose to modify features that you would use to predict the performance of the students on your chosen response variable. \n",
    "\n",
    "You can also create your own features. For example, perhaps you figured that maybe a state's expenditure per student may affect their overall academic performance so you create a expenditure_per_student feature.\n",
    "\n",
    "Use this space to modify or create features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"exp_per_student\"] = df[\"TOTAL_EXPENDITURE\"]/df[\"GRADES_4_G\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering justification: I like to lol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Visualization</h2>\n",
    "\n",
    "Investigate the relationship between your chosen response variable and at least two predictors using visualizations. Write down your observations.\n",
    "\n",
    "**Visualization 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not sure how to visualize this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "most likely the visualizations would indicate a positive/negative linear relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "most likely the visualizations would indicate a positive/negative linear relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Data Creation </h2>\n",
    "\n",
    "_Use this space to create train/test data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['ENROLL_8','AVG_MATH_8_SCORE','exp_per_student']].dropna()\n",
    "y = df.loc[X.index]['AVG_READING_8_SCORE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "      X, y, test_size= 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Prediction </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML Models [Resource](https://medium.com/@vijaya.beeravalli/comparison-of-machine-learning-classification-models-for-credit-card-default-data-c3cf805c9a5a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import your sklearn class here\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create your model here\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose some metrics to evaluate the performance of your model, some of them are mentioned in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(model.predict(X_test)-y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have copied over the graphs that visualize the model's performance on the training and testing set. \n",
    "\n",
    "Change `col_name` and modify the call to `plt.ylabel()` to isolate how a single predictor affects the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'AVG_MATH_4_SCORE'\n",
    "\n",
    "f = plt.figure(figsize=(12,6))\n",
    "plt.scatter(X_train[col_name], y_train, color = \"red\")\n",
    "plt.scatter(X_train[col_name], model.predict(X_train), color = \"green\")\n",
    "\n",
    "plt.legend(['True Training','Predicted Training'])\n",
    "plt.xlabel(col_name)\n",
    "plt.ylabel('Reading 8 Score')\n",
    "plt.title(\"Model Behavior On Training Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'AVG_MATH_4_SCORE'\n",
    "\n",
    "f = plt.figure(figsize=(12,6))\n",
    "plt.scatter(X_test[col_name], y_test, color = \"blue\")\n",
    "plt.scatter(X_test[col_name], model.predict(X_test), color = \"black\")\n",
    "\n",
    "plt.legend(['True testing','Predicted testing'])\n",
    "plt.xlabel(col_name)\n",
    "plt.ylabel('Reading 8 Score')\n",
    "plt.title(\"Model Behavior on Testing Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Summary </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the correlation between 4th-grade math scores and 8th-grade reading scores, the visualizations indicated a positive relationship. A linear regression model was fitted, demonstrating a reasonable fit. Findings suggest a potential association between math and reading proficiency across grade levels."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "6cf8df3ff69f85f626faf55c10df6fe2cb9d1236b4dc73844ee4dc01369c2c99"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
